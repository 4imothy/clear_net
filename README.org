* [[https://en.wikipedia.org/wiki/C_(programming_language)][C]]learNet

** [[https://en.wikipedia.org/wiki/C_(programming_language)][C]] + Learn + Net
A single file /C/ library for the creation and training of vanilla and convolutional neural nets whose only dependency is /C/ itself.
Check out some of the examples in the [[./examples][examples]] directory.

*Some Features*
- Creation and training of vanilla and convolutional models
- Autodifferentiation engine
- Stochastic gradient descent and other optimization methods
- Saving and loading a model to a file

** List of Functions
All of these functions are used in files in the [[./examples][examples]] directory.
- *[[./examples/xor.c][xor]]:* Vanilla net creation and training on xor
- *[[./examples/lin_reg.c][lin reg]]:* Vanilla net creation and training on simple linear regression example
- *[[./examples/iris.c][iris]]:* Vanilla net creation and training with stochastic gradient descent on the iris dataset
- *[[./examples/full_adder.c][full adder]]:* Vanilla net creation and training with momentum on full adder operation
- *[[./examples/mnist_vanilla.c][mnist vanilla]]:* Vanilla net creation and training with momentum and stochastic gradient descent on mnist dataset
- *[[./examples/mnist_mix.c][mnist mix]]:* Convolutional net with some dense layers creation and training with momentum and stochastic gradient descent on mnist dataset
- *[[./examples/mnist_conv.c][mnist convolutional]]:* Fully convolutional net creation and training stochastic gradient descent on mnist dataset

*** Autodifferentiation Engine
The differentiation engine runs on a gradient store which stores the computation graph which is used to find the gradients of each value. Since must store all the computations you have to pass it as a reference to every function. Each mathematical function returns a digit which is a relative pointer to the elements location in the gradent store, these are the indices passed to the mathematical operations. Call backward on a element to find the gradient of every element relative to that one. The gradient can be accessed with the GET_NODE macro and grabbing the grad element with .grad `GET_NODE(1).grad`.

| Name                                                              | What it Does                                                                          |
|-------------------------------------------------------------------+---------------------------------------------------------------------------------------|
| GradientStore cn_alloc_gradient_store(size_t length)              | Create a gradient store with the max length given                                     |
| void cn_realloc_gradient_store(GradientStore *gs, size_t new_len) | Reallocate the gradient store with the new max length given                           |
| void cn_dealloc_gradient_store(GradientStore *nl)                 | Deallocate a gradient store                                                           |
| size_t cn_init_leaf_var(GradientStore *nl, float num)             | Create a leaf node on the store that wasn't the result of any computation             |
| size_t cn_add(GradientStore *nl, size_t left, size_t right)       | Add the two given nodes and return the result                                         |
| size_t cn_subtract(GradientStore *nl, size_t left, size_t right)  | Subtract the two given nodes and return the result                                    |
| size_t cn_multiply(GradientStore *nl, size_t left, size_t right)  | Multiply the two given nodes and return the result                                    |
| size_t cn_raise(GradientStore *gs, size_t to_raise, size_t pow)   | Raise the first node to the second node and return the result                         |
| size_t cn_reluv(GradientStore *nl, size_t x)                      | Do ReLU on the node                                                                   |
| size_t cn_hyper_tanv(GradientStore *nl, size_t x)                 | Do Tanh on the node                                                                   |
| size_t cn_sigmoidv(GradientStore *nl, size_t x)                   | Do Sigmoid on the node                                                                |
| size_t cn_leaky_reluv(GradientStore *nl, size_t x)                | Do Leaky ReLU on the node                                                             |
| size_t cn_eluv(GradientStore *gs, size_t x)                       | Do ELU on the node                                                                    |
| void cn_backward(GradientStore *nl, size_t y)                     | Find the gradient of each value relative to the one given                             |
| GET_NODE(id) (gs)->vars[(id)]                                     | Get the node at the given index, must have a reference to a gradient store named `gs` |

*** Linear Algebra
A vector and matrix type are used internally and as the types of the inputs and outputs of each model. There is also a struct called LAData which can store eithor a vector or matrix.
| Model Type    | Input            | Output                                                |
|---------------+------------------+-------------------------------------------------------|
| Vanilla       | Vector           | Vector                                                |
| Convolutional | List of Matrices | LAData (Vector or Matrix depending on the last layer) |

| Name                                                                             | What it Does                                                 |
|----------------------------------------------------------------------------------+--------------------------------------------------------------|
| Matrix cn_alloc_matrix(size_t nrows, size_t ncols)                               | Allocate a matrix with given rows and cols                   |
| void cn_dealloc_matrix(Matrix *mat)                                              | Deallocate a matrix                                          |
| Matrix cn_form_matrix(size_t nrows, size_t ncols, size_t stride, float *elements | Form a matrix with the given rows, cols, stride and elements |
| void cn_print_matrix(Matrix mat, char *name)                                     | Print the matrix                                             |
| Vector cn_alloc_vector(size_t nelem)                                             | Allocte a vector with the given number of elements           |
| void cn_dealloc_vector(Vector *vec)                                              | Deallocate a vector                                          |
| Vector cn_form_vector(size_t nelem, float *elements)                             | Form a vector around given elements                          |
| void cn_print_vector_inline(Vector vec)                                          | Print vector elements inline                                 |

*** Hyper Parameters
*Default Hyperparameters:*
- Learning Rate: 0.01
- Number of layers: 0
- Number of parameters: 0
- Negative scale applied to negative values in activation functions: 0.1
- Does model use momentum when training: No
  - Model momentum beta: 0

| Name                                       | What it Does                                                         |
|--------------------------------------------+----------------------------------------------------------------------|
| void cn_default_hparams(void)              | Set the default parameters descried above                            |
| void cn_with_momentum(float momentum_beta) | Net will now use momentum when training with the provided beta value |
| void cn_set_neg_scale(float neg_scale)     | Set the scale to apply to negative values in activation functions    |
| void cn_set_rate(float rate)               | Set the learning rate to the provided value                          |

*** Activation Funtions
*Possible Functions (these are all enum values)*
- Sigmoid
- ReLU
- Tanh
- LeakyReLU
- ELU

| Name                                       | What it Does                      |
|--------------------------------------------+-----------------------------------|
| float cn_sigmoid(float x)                  | Do Sigmoid to given value         |
| float cn_relu(float x)                     | Do ReLU to given value            |
| float cn_hyper_tan(float x)                | Do Tahn to given value            |
| float cn_leaky_relu(float x)               | Do Leaky ReLU to given value      |
| float cn_elu(float x)                      | Do ELU to given value             |
| float cn_activate(float x, Activation act) | Do activation with given function |

*** Net
| Name                                                                                                                                    | What it Does                                                            |
|-----------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------|
| Net cn_init_net(void)                                                                                                                   | Initialize a net                                                        |
| void cn_dealloc_net(Net *net)                                                                                                           | Deallocate a net                                                        |
| void cn_randomize_net(Net net, float lower, float upper)                                                                                | Randomize the parameters in a net                                       |
| void cn_shuffle_van_input(Matrix *input, Matrix *target)                                                                                | Shuffle the input and target matrices of a vanilla neural net           |
| void cn_get_batch_van(Matrix *batch_in, Matrix *batch_tar, Matrix all_input, Matrix all_target, size_t batch_num, size_t batch_size)    | Get a batch of vanilla inputs and outputs from the given matrices       |
| void cn_shuffle_conv_input(Matrix ***input, LAData **targets, size_t len)                                                               | Shuffle the input list of lists matrices and the list of LAData targets |
| void cn_get_batch_conv(Matrix **batch_in, LAData *batch_tar, Matrix **all_input, LAData *all_target, size_t batch_num, size_t batch_size) | Get a batch of convolutional inputs and outputs                         |
| void cn_save_net_to_file(Net net, char *file_name)                                                                                      | Save given net to file with the given name                              |
| Net cn_alloc_net_from_file(char *file_name)                                                                                             | Allocate net from file with the given name                              |
| void cn_print_net(Net net, char *name)                                                                                                  | Print the net with all of its layers and parameters                     |

**** Vanilla Net
| Name                                                                         | What it Does                                                               |
|------------------------------------------------------------------------------+----------------------------------------------------------------------------|
| float cn_learn_vani(Net *net, Matrix input, Matrix target)                   | Teach the vanilla net on the given input and output                        |
| Vector cn_predict_vani(Net net, Vector input)                                | Get the prediction given the input                                         |
| float cn_loss_vani(Net net, Matrix input, Matrix target)                     | Get the loss of the net on the given input and output                      |
| void cn_print_vani_results(Net net, Matrix input, Matrix target)             | Print the inputs, outputs and targets to compare                           |
| void cn_print_target_output_pairs_vani(Net net, Matrix input, Matrix target) | Print the vector output and target on top of eachother for easy comparison |

**** Convolutional Net
| Name                                                                           | What it Does                                              |
|--------------------------------------------------------------------------------+-----------------------------------------------------------|
| float cn_learn_conv(Net *net, Matrix **inputs, LAData *targets, size_t nimput) | Teach the convolutional net on the given input and output |
| LAData cn_predict_conv(Net *net, Matrix *input)                                | Get the prediction of the net given the input             |
| float cn_loss_conv(Net *net, Matrix **input, LAData *targets, size_t nimput)   | Get the loss of the net on the given input and output     |
*** Dense Layer
| Name                                                                                     | What it Does                                               |
|------------------------------------------------------------------------------------------+------------------------------------------------------------|
| void cn_alloc_dense_layer(Net *net, Activation act, size_t dim_input, size_t dim_output) | Allocate a dense layer as the first layer on the given net |
| void cn_alloc_secondary_dense_layer(Net *net, Activation act, size_t dim_output)         | Allocate a secondary dense layer on the given net          |
| Vector cn_forward_dense(DenseLayer *layer, Vector prev_output)                           | Perform the forward operation on the layer                 |

*** Convolutional Layer
| Name                                                                                                                                    | What it Does                                                       |
|-----------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------|
| void cn_alloc_conv_layer(Net *net, Padding padding, Activation act, size_t nimput, size_t noutput, size_t input_nrows, size_t input_ncols, size_t kernel_nrows, size_t kernel_ncols) | Allocate a convolutional layer as the first layer of the given net |
| void cn_alloc_secondary_conv_layer(Net *net, Padding padding, Activation act, size_t noutput, size_t kernel_nrows, size_t kernel_ncols) | Allocatate a secondary convolutional layer                         |
| Matrix* cn_forward_conv(ConvolutionalLayer *layer, Matrix *input)                                                                       | Perform the forward operation on the layer                         |
| float cn_correlate(Matrix kern, Matrix input, long top_left_row, long top_left_col)                                                     | Correlate the given matrix starting at the given indices with the given kernel |

*** Pooling Layers
**** Normal
| Name                                                                                                   | What it Does                              |
|--------------------------------------------------------------------------------------------------------+-------------------------------------------|
| void cn_alloc_pooling_layer(Net *net, PoolingStrategy strat, size_t kernel_nrows, size_t kernel_ncols) | Allocate a pooling layer on the given net |
| Matrix* cn_pool_layer(PoolingLayer *pooler, Matrix *input)                                             | Pool a given list of matrices             |

**** Global
| Name                                                                   | What it Does                                     |
|------------------------------------------------------------------------+--------------------------------------------------|
| void cn_alloc_global_pooling_layer(Net *net, PoolingStrategy strat)    | Allocate a global pooling layer on the given net |
| Vector cn_global_pool_layer(GlobalPoolingLayer *pooler, Matrix *input) | Globally pool the given list of matrices         |
